**1. Probabilities and Statistics refresher**

&#10230; Repaso de Probabilidades y Estadísticas

<br>

**2. Introduction to Probability and Combinatorics**

&#10230; Introducción a la Probabilidad y Combinatoria

<br>

**3. Sample space ― The set of all possible outcomes of an experiment is known as the sample space of the experiment and is denoted by S.**

&#10230; Espacio Muestral - El conjunto de todos los posibles resultados de un experimento es conocido como el espacio muestral del experimento y se denota como S.

<br>

**4. Event ― Any subset E of the sample space is known as an event. That is, an event is a set consisting of possible outcomes of the experiment. If the outcome of the experiment is contained in E, then we say that E has occurred.**

&#10230; Evento - Cualquier subconjunto del espacio muestral es conocido como un evento. Esto significa que un evento es un conjunto de posibles resultados de un experimento. Si el resultado de un experimento esta contenido en E, entonces decimos que el evento E ha ocurrido.

<br>

**5. Axioms of probability - For each event E, we denote P(E) as the probability of event E occuring.**

&#10230; Axiomas de la probabilidad - Para cada evento E, denotamos P(E) como la probabilidad de que el evento E ocurra.

<br>

**6. Axiom 1 ― Every probability is between 0 and 1 included, i.e:**

&#10230; Axioma 1 - Cada probabilidad tiene valores inclusivos entre 0 y 1, esto es:

<br>

**7. Axiom 2 ― The probability that at least one of the elementary events in the entire sample space will occur is 1, i.e:**

&#10230; Axioma 2 - La probabilidad de que por lo menos uno de los eventos elementales de todo el espacio muestral ocurra es 1, esto es:

<br>

**8. Axiom 3 ― For any sequence of mutually exclusive events E1,...,En, we have:**

&#10230; Axioma 3 - Por cada secuencia de eventos mutuamente excluyentes E1,...,En, se tiene:

<br>

**9. Permutation ― A permutation is an arrangement of r objects from a pool of n objects, in a given order. The number of such arrangements is given by P(n,r), defined as:**

&#10230; Permutación - Una permutación es un arreglo de r objetos tomados de un grupo de n objetos, en un order arbitrario. El número de estos arreglos es dado por P(n,r), definido como:

<br>

**10. Combination ― A combination is an arrangement of r objects from a pool of n objects, where the order does not matter. The number of such arrangements is given by C(n,r), defined as:**

&#10230; Combinación - Una combinación es un arreglo de r objetos tomados de un grupo de n objetos, donde el orden no importa. El número de estos arreglos es dado por C(n,r), definido como:

<br>

**11. Remark: we note that for 0⩽r⩽n, we have P(n,r)⩾C(n,r)**

&#10230; Observación: cabe resaltar que para 0⩽r⩽n, se tiene P(n,r)⩾C(n,r)

<br>

**12. Conditional Probability**

&#10230; Probabilidad Condicional

<br>

**13. Bayes' rule ― For events A and B such that P(B)>0, we have:**

&#10230; Regla de Bayes - Para eventos A y B tal que P(B)>0, se tiene:

<br>

**14. Remark: we have P(A∩B)=P(A)P(B|A)=P(A|B)P(B)**

&#10230; Observación: Se tiene P(A∩B)=P(A)P(B|A)=P(A|B)P(B)

<br>

**15. Partition ― Let {Ai,i∈[[1,n]]} be such that for all i, Ai≠∅. We say that {Ai} is a partition if we have:**

&#10230; Partición - Sea {Ai,i∈[[1,n]]} tal que para todo i, Ai≠∅. Se dice entonces que {Ai} es una partición si se cumple:

<br>

**16. Remark: for any event B in the sample space, we have P(B)=n∑i=1P(B|Ai)P(Ai).**

&#10230; Observación: Para cualquier evento B del espacio muestral, se cumple P(B)=n∑i=1P(B|Ai)P(Ai).

<br>

**17. Extended form of Bayes' rule ― Let {Ai,i∈[[1,n]]} be a partition of the sample space. We have:**

&#10230; Regla de Bayes extendida - Sea {Ai,i∈[[1,n]]} una partición del espacio muestral. Se cumple:

<br>

**18. Independence ― Two events A and B are independent if and only if we have:**

&#10230; Independencia - Dos events A y B son independientes si y solo si se cumple:

<br>

**19. Random Variables**

&#10230; Variables Aleatorias

<br>

**20. Definitions**

&#10230; Definiciones

<br>

**21. Random variable ― A random variable, often noted X, is a function that maps every element in a sample space to a real line.**

&#10230; Variable Aleatoria - Una variable aleatoria, generalmente denotada por X, es una función que asocia cada elemento de un espacio muestral a una linea real.

<br>

**22. Cumulative distribution function (CDF) ― The cumulative distribution function F, which is monotonically non-decreasing and is such that limx→−∞F(x)=0 and limx→+∞F(x)=1, is defined as:**

&#10230; Función de distribución acumulada (FDA) - La función de distribución acumulada F, la cual es monótonamente creciente y es tal que limx→−∞F(x)=0 y limx→+∞F(x)=1, es definida como:

<br>

**23. Remark: we have P(a<X⩽B)=F(b)−F(a).**

&#10230; Observación: Se tiene P(a<X⩽B)=F(b)−F(a).

<br>

**24. Probability density function (PDF) ― The probability density function f is the probability that X takes on values between two adjacent realizations of the random variable.**

&#10230; Función de densidad de Probabilidad (FDP) - La función de densidad de probabilidad f es la probabilidad que X tome valores entre dos ocurrencias adyacentes de la variable aleatoria.

<br>

**25. Relationships involving the PDF and CDF ― Here are the important properties to know in the discrete (D) and the continuous (C) cases.**

&#10230; Relaciones entre la FDA y FDP - Estas son las propiedades mas importantes para conocer en los casos discreto (D) y contínuo (C).

<br>

**26. [Case, CDF F, PDF f, Properties of PDF]**

&#10230; [Caso, FDA F, FDP f, Propiedades de FDP]

<br>

**27. Expectation and Moments of the Distribution ― Here are the expressions of the expected value E[X], generalized expected value E[g(X)], kth moment E[Xk] and characteristic function ψ(ω) for the discrete and continuous cases:**

&#10230; Valor Esperado y Momentos de la Distribución - Aquí están las expresiones del valor esperado E[X], valor esperado generalizado E[g(X)], k-ésimo momento E[Xk] y función característica ψ(ω) para los casos discreto y contínuo:

<br>

**28. Variance ― The variance of a random variable, often noted Var(X) or σ2, is a measure of the spread of its distribution function. It is determined as follows:**

&#10230; Varianza - La varianza de una variable aleatoria, frecuentemente denotada por Var(X) o σ2, es la medida de dispersión de su función de distribución. Esta determinada de la siguiente manera:

<br>

**29. Standard deviation ― The standard deviation of a random variable, often noted σ, is a measure of the spread of its distribution function which is compatible with the units of the actual random variable. It is determined as follows:**

&#10230; Desviación estándar - La desviación estándar de una variable aleatoria, frecuentemente denotada por σ, es una medida de la dispersión de su función de distribución la cual es compatible con las unidades de la correspondiente variable aleatoria. Se determina de la siguiente manera:

<br>

**30. Transformation of random variables ― Let the variables X and Y be linked by some function. By noting fX and fY the distribution function of X and Y respectively, we have:**

&#10230; Transformación de variables aleatorias - Sean las variables X y Y asociadas por alguna función. Denotemos como fX y fY la función de distribución de X y Y respectivamente, se tiene:

<br>

**31. Leibniz integral rule ― Let g be a function of x and potentially c, and a,b boundaries that may depend on c. We have:**

&#10230; Regla integral de Leibniz - Sea g una función de x y posiblemente de c, y además sea a,b un intervalo que puede depender de c. Se tiene: 

<br>

**32. Probability Distributions**

&#10230; Distribuciones de Probabilidad

<br>

**33. Chebyshev's inequality ― Let X be a random variable with expected value μ. For k,σ>0, we have the following inequality:**

&#10230; Desigualdad de Chebyshev - Sea X una variable aleatoria con valor esperado μ. Para k,σ>0, se tiene la siguiente desigualdad:

<br>

**34. Main distributions ― Here are the main distributions to have in mind:**

&#10230; Distribuciones importantes - Aquí están las distribuciones más importantes para tomar en cuenta:

<br>

**35. [Type, Distribution]**

&#10230; [Tipo, Distribución]

<br>

**36. Jointly Distributed Random Variables**

&#10230; Variables aleatorias conjuntas

<br>

**37. Marginal density and cumulative distribution ― From the joint density probability function fXY , we have**

&#10230; Densidad marginal y distribución acumulada - De la función conjunta de densidad de probabilidad fXY , se tiene

<br>

**38. [Case, Marginal density, Cumulative function]**

&#10230; [Caso, Densidad marginal, Función acumulativa]

<br>

**39. Conditional density ― The conditional density of X with respect to Y, often noted fX|Y, is defined as follows:**

&#10230; Densidad condicional - La densidad condicional de X con respecto a Y, frecuentemente denotada como fX|Y, es definida como:

<br>

**40. Independence ― Two random variables X and Y are said to be independent if we have:** 

&#10230; Independencia - Dos variables aleatorias X y Y son consideradas independientes si se tiene:

<br>

**41. Covariance ― We define the covariance of two random variables X and Y, that we note σ2XY or more commonly Cov(X,Y), as follows:**

&#10230; Covarianza - Definimos la covarianza de dos variables aleatorias X y Y, denotada como σ2XY o comúnmente como Cov(X,Y), de la siguiente manera:

<br>

**42. Correlation ― By noting σX,σY the standard deviations of X and Y, we define the correlation between the random variables X and Y, noted ρXY, as follows:**

&#10230; Correlación - Sean σX,σY las desviaciones estándard de X y Y, definimos la correlación entre estas variables, denotada como ρXY, de la siguiente manera:

<br>

**43. Remark 1: we note that for any random variables X,Y, we have ρXY∈[−1,1].**

&#10230; Observación 1: Cabe resaltar que para X,Y variables aleatorias cualesquiera, se tiene que ρXY∈[−1,1].

<br>

**44. Remark 2: If X and Y are independent, then ρXY=0.**

&#10230; Observación 1: Si X y Y son independientes, entonces ρXY=0.

<br>

**45. Parameter estimation**

&#10230; Estimación de Parámetros

<br>

**46. Definitions**

&#10230; Definiciones

<br>

**47. Random sample ― A random sample is a collection of n random variables X1,...,Xn that are independent and identically distributed with X.**

&#10230; Muestra Aleatoria - Una muestra aleatoria es una colección de n variables aleatorias X1,...,Xn que son independientes e idénticamente distribuidas a X.

<br>

**48. Estimator ― An estimator is a function of the data that is used to infer the value of an unknown parameter in a statistical model.**

&#10230; Estimador - Un estimador es una función de los datos que es usada para inferir el valor de un parámetro desconocido en un modelo estadístico.

<br>

**49. Bias ― The bias of an estimator ^θ is defined as being the difference between the expected value of the distribution of ^θ and the true value, i.e.:**

&#10230; Sesgo - El sesgo de un estimador ^θ se define como la diferencia entre el valor esperado de la distribución de ^θ y el valor exacto, esto es:

<br>

**50. Remark: an estimator is said to be unbiased when we have E[^θ]=θ.**

&#10230; Observación: se dice que un estimador es no sesgado cuando se tiene E[^θ]=θ.

<br>

**51. Estimating the mean**

&#10230; Estimación de la media

<br>

**52. Sample mean ― The sample mean of a random sample is used to estimate the true mean μ of a distribution, is often noted ¯¯¯¯¯X and is defined as follows:**

&#10230; Media de la muestra - La media de la muestra aleatoria se usa para estimar el valor exacto de la media μ de la distribución, se denota frecuentemente como ¯¯¯¯¯X y se define de la siguiente manera:

<br>

**53. Remark: the sample mean is unbiased, i.e E[¯¯¯¯¯X]=μ.**

&#10230; Observación: La media de la muestra es no sesgada, esto es E[¯¯¯¯¯X]=μ.

<br>

**54. Central Limit Theorem ― Let us have a random sample X1,...,Xn following a given distribution with mean μ and variance σ2, then we have:**

&#10230; Teorema del Límite Central - Sea X1,...,Xn una muestra aleatoria que sigue una distribución con media μ y varianza σ2, entonces se tiene:

<br>

**55. Estimating the variance**

&#10230; Estimación de la varianza

<br>

**56. Sample variance ― The sample variance of a random sample is used to estimate the true variance σ2 of a distribution, is often noted s2 or ^σ2 and is defined as follows:**

&#10230; Varianza de la muestra - La varianza de la muestra aleatoria se usa para estimar el valor exacto de la varianza σ2 de una distribución, se denota frecuentemente como s2 o ^σ2 y se define de la siguiente manera:

<br>

**57. Remark: the sample variance is unbiased, i.e E[s2]=σ2.**

&#10230; Observación: La varianza de la muestra es no sesgada, esto es E[s2]=σ2.

<br>

**58. Chi-Squared relation with sample variance ― Let s2 be the sample variance of a random sample. We have:**

&#10230; Relación Chi-cuadrada con la varianza de la muestra - Sea s2 la varianza de la muestra de una variable aleatoria. Se tiene:

<br>

**59. [Introduction, Sample space, Event, Permutation]**

&#10230; [Introducción, Espacio Muestral, Evento, Permutación]

<br>

**60. [Conditional probability, Bayes' rule, Independence]**

&#10230; [Probabilidad condicional, Regla de Bayes, Independencia]

<br>

**61. [Random variables, Definitions, Expectation, Variance]**

&#10230; [Variables aleatorias, Definiciones, Valor esperado, Varianza]

<br>

**62. [Probability distributions, Chebyshev's inequality, Main distributions]**

&#10230; [Distribuciones de probabilidad, Desigualdad de Chebyshev, Principales Distribuciones]

<br>

**63. [Jointly distributed random variables, Density, Covariance, Correlation]**

&#10230; [Variables aleatorias distribuidas conjuntamente, Densidad, Covarianza, Correlación]

<br>

**64. [Parameter estimation, Mean, Variance]**

&#10230; [Estimación de Parámetros, Media, Varianza]
